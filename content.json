{"meta":{"title":"funny blog","subtitle":"","description":"i get angry at software","author":"Alice Vee","url":"https://kamadoori.github.io","root":"/"},"pages":[],"posts":[{"title":"Even better type-safe Electron IPCs","slug":"even-better-type-safe-electron-ipcs","date":"2023-11-24T19:00:00.000Z","updated":"2023-11-24T21:00:30.764Z","comments":true,"path":"2023/11/24/even-better-type-safe-electron-ipcs/","link":"","permalink":"https://kamadoori.github.io/2023/11/24/even-better-type-safe-electron-ipcs/","excerpt":"","text":"Woo! Type-safety has been achieved! And I managed to also completely generalize it. If I want to add a method to the API, I simply need to add the signature to the interface and the implementation to an object. Everything else remains as it has been! The last time I looked at this, I closed the ordeal by saying “You cannot use any functions with names that aren’t in this type, hooray” and basically left it at that. Thing is, Typescript’s type system is SO much more flexible than that, and there’s so much more to discover. So what changed since last time? Type mappingI look a look at type mapping. Let’s say I write a function signature: type doThing = (foo: Foo, bar: Bar) => Baz; What if I want to have a version of this signature, but not include the foo parameter? The simple solution would just be to create another type: type doAnotherThing = (bar: Bar) => Baz; This works.. but if I have multiple functions that I want to treat this way, obviously that’s not really a way to go about it. This is where type mapping comes handy. With type mapping, you can create types that are based on other types: type HasPropsWithTypeString = &#123; [key: string]: string; foo: string; &#125;; // We can map this to give back other data types instead: type HasPropsWithTypeNumber = &#123; [someKey in keyof HasPropsWithTypeString]: number; &#125;; What this code does is take all keys from HasPropsWithTypeString and say that an object with this new type will return numbers when these keys are addressed. Typescript now treats objects with this type as having a prop foo that’s a number. Even better when constructing an object of this type, having a foo number prop becomes a requirement. If you do not include it, Typescript will let you know: Property &#39;foo&#39; is missing in type &#39;&#123;&#125;&#39; but required in type &#39;givesN&#39;. So what if we apply that to our own API? export interface ElectronAPI &#123; doThing(event: IpcMainInvokeEvent, someArgument: string): boolean; doAnotherThing(event: IpcMainInvokeEvent, anotherArgument: number); doThirdThing(event: IpcMainInvokeEvent); &#125; Relatively standard API example. Now, I’ve got this magic prop eraser type, it’ll remove the first prop from these methods: type RemoveEvent&lt;Fun> = Fun extends ( event: IpcMainInvokeEvent, ...args: infer Param ) => infer Result ? (...args: Param) => Result : never; This is a bit more of an advanced mapping, so let’s go over it. RemoveEvent&lt;Fun&gt; &#x3D;&gt; Generic types. This generic type is named Fun here, after Function. Not after enjoyment, we’re still programmers, so we don’t get to have fun. Fun extends (/* snip */) =&gt; &#x3D;&gt; Conditional typing. This allows you to map a type depending on what’s incoming. In this case, if the incoming type is a type that starts with an event parameter of type IpcMainInvokeEvent, then it maps to the type after the ?, otherwise it maps to the type after the :. This is exactly the same as a ternary operator. infer Param, infer Result &#x3D;&gt; Tells Typescript to infer the type that these two things are based on the context. So if a function with a signature of (event: IpcMainInvokeEvent, foo: number): string came in, Param will be inferred to be (foo: string), and Result will be inferred to be string. never &#x3D;&gt; declare that this situation should not occur. In other words, if our function does not match the pattern of the extends type, we are intentionally making this type useless. So how do we use this now? We can simply pass in functions to the type parameter: // Note: Can't access these properties with dot notation. However, there is type safety on the linter for bracket notation. type doThingMapped = RemoveEvent&lt;ElectronAPI[\"doThing\"]>; type doAnotherThingMapped = RemoveEvent&lt;ElectronAPI[\"doAnotherThing\"]>; If a function now uses this as its type, it’ll show the exact same parameters and return type as the original, without the event parameter. Cool, huh? Though, this could be applied a little bit more generic instead… export type ElectronRendererAPI = &#123; [key in keyof ElectronAPI]: RemoveEvent&lt;ElectronAPI[key]>; &#125;; Beautiful. This will essentially map all existing functions in ElectronAPI to the RemoveEvent type, passing the current function in as parameter. It turns out that key is actually defined (and usable) as variable here, so using it in this manner means that you simply select the property! Now I can do the same thing for the Main thread of the application. When Electron ipc methods are called, they put all arguments in a rest parameter, which is an array of type any. You have to destructure this yourself again, but you do want the right type hints to exist in the main-thread part of the code still. If you don’t type args as any[], you can’t access it as an array with type hinting. So, let’s do the same trick, but instead of mapping it so it removes the event parameter, let’s map it so it instead removes every other parameter and adds an ...args parameter: type RemoveParams&lt;Fun> = Fun extends ( event: IpcMainInvokeEvent, ...args: infer Param ) => infer Result ? (event: IpcMainInvokeEvent, ...args: any[]) => Result : never; export type ElectronMainAPI = &#123; [key in keyof ElectronAPI]: RemoveParams&lt;ElectronAPI[key]>; &#125;; And that’s what my channels.ts file now looks like! To define the API on the main thread side: const api: ElectronMainAPI = &#123; // Note: Automatic type hinting on the parameters and return type! doThing: async (_event, args) => &#123; const arg1 = args[0]; const result = await doSomethingAsync(arg1); return result.success; &#125;, /* Snip: define the other methods here too */ &#125;; In my main.ts, to register handlers: Object.keys(api).forEach((key) => &#123; ipcMain.handle(key, api[key as keyof ElectronAPI]); &#125;); Then in my preload.ts, to expose the methods in the renderer thread: // This is simply an object we load up with `invoke` calls for all the ipc channels by reading the original `api` object and applying the functions from that to this. const exposed = &#123;&#125; as ElectronRendererAPI; Object.keys(api).forEach((key) => &#123; exposed[key as keyof ElectronRendererAPI] = (...args: any[]) => ipcRenderer.invoke(key.toString(), args); &#125;); contextBridge.exposeInMainWorld(\"ElectronAPI\", exposed); And that’s it. Completely generalized and (almost) completely typed Electron ipc API. The only missing link is easier typing for called ipc methods in the main thread, where now everything is stuffed inside of an args argument, but I am unsure on how to fix that. Maybe instead pass in an options object, and always destructure the first argument in the args object to match a predefined type for every function in ElectronAPI? It might be possible, but I am going to stop here. Parsing arguments is a very minor holdup and not very sensitive to syntax errors, instead being sensitive to symantic errors. I’m happy with what I achieved here.","categories":[],"tags":[]},{"title":"Type-safe Electron IPCs","slug":"type-safe-electron-ipcs","date":"2023-11-18T19:00:00.000Z","updated":"2023-11-24T21:00:30.768Z","comments":true,"path":"2023/11/18/type-safe-electron-ipcs/","link":"","permalink":"https://kamadoori.github.io/2023/11/18/type-safe-electron-ipcs/","excerpt":"","text":"Typescript is awesome. Electron, not so much I think. Tauri is generally considered the superior option, as it’s faster, you can write code in a supposedly more enjoyable language and it provides smaller package sizes. However, Electron’s benefit is that your codebase can exist with only a single language used in it. There is a problem whenever you try to incorporate a browser window as an application with any software, and that is protection of the user’s device. With Chromium-based browsers and applications, you are sandboxing the rendering window from the rest of your OS, only allowing certain calls to send data to and retrieve data from the OS. Electron enables this with their own IPC implementation. IPC, or Inter-Process Communication, allows two separate processes to share data with one another. Electron needs to do this, as the part of the package that handles interaction with the computer (application menu, dialogs) is otherwise completely separated from the rendering part of the application (your website-turned-windows-app). The electron IPC implementation is not too difficult to wrap your head around. You have three components to it: your main file (main process), your preload file (main process) and your html&#x2F;js side (renderer process). To create an IPC channel between your main process and rendering process, you have to insert code in all three of these files. There are two ways to do so, but I will only explore the modern two-way approach of sending&#x2F;receiving data to and from the main process. First, the main.js file. This is what a cut-down version of your main.js may look like: import &#123; app, BrowserWindow, ipcMain &#125; from \"electron\"; import path from \"node:path\"; app.whenReady().then(() => &#123; ipcMain.handle(\"doThing\", async (event, args) => &#123; await doThing(); /* Do something that requires access to your OS (filesystem, registry etc) here */ return \"done\"; &#125;); const mainWindow = new BrowserWindow(&#123; webPreferences: &#123; preload: path.join(__dirname, \"preload.js\"), &#125;, &#125;); &#125;); Quite simple. You have what’s essentially an event listener waiting for a call to the doThing channel, it does a thing, then it sends back the result. By making it async we don’t have to fiddle around with callbacks quite the same way; bless modern Javascript features. Now, preload.js. This is not actually a cut-down version, your preload can be quite small: import &#123; contextBridge, ipcRenderer &#125; from \"electron\"; contextBridge.exposeInMainWorld(\"electronAPI\", &#123; doThing: () => ipcRenderer.invoke(\"doThing\"), &#125;); So what does this do? The function name exposeInMainWorld should serve as somewhat of an indication, but to be specific, this puts an electronAPI object onto the renderer process’s window object. The electronAPI object will contain all properties of the object passed as the second parameter, allowing the renderer thread to call these specific methods (and ONLY these methods, for safety). Usage of these methods becomes clear if we look at any file in the actual website that wants to use it, so let’s make a very simple index.html: &lt;!DOCTYPE html> &lt;html> &lt;head> &lt;title>Site&lt;/title> &lt;/head> &lt;body> &lt;p id=\"stuff-in-here\">Stuff!&lt;/p> &lt;button type=\"button\" id=\"btn\">Click me!&lt;/button> &lt;script defer> const p = document.getElementById(\"stuff-in-here\"); const btn = document.getElementById(\"btn\"); btn.addEventListener(\"click\", async () => &#123; const returnedValue = await window.electronAPI.doThing(); p.innerText = returnedValue; &#125;); &lt;/script> &lt;/body> &lt;/html> A simple setup; we have a button, and when you click it, doThing() is called, and the value you get back from it is put in the only paragraph element. These are the three elements there are to Electron IPC. There’s one big problem to this approach however and that is type safety. I’m creating a Nuxt 3 application, which uses Typescript for everything. I want to make sure that the types I send and retrieve are of a certain value type, and I want to be able to use that type safety in my frontend code as well as in my Electron code. How do I go about this? I have not gotten too far into this, but I have found a semi-solution that works for me. I have added a few pieces of code, some of it specifically available to Electron: // in Electron's main.ts: function addIpcMainHandler( channel: AllowedChannels, func: ElectronApiFunction ) &#123; ipcMain.handle(channel, func); &#125; // Then, in the bootstrapping process: addIpcMainHandler(\"doThing\", async () => &#123; const result = await doSomethingWithLocalFs(); return result; &#125;); // in Electron's preload.ts: function addIpcRendererHandler(api: any, channel: AllowedChannels) &#123; api[channel] = (...args: any[]) => ipcRenderer.invoke(channel, args); &#125; const api = &#123;&#125;; addIpcRendererHandler(api, \"doThing\"); contextBridge.exposeInMainWorld(\"ElectronAPI\", api); This doesn’t look too type-safe yet, does it? Here is where my shared/ folder comes in: // shared/ipc/channels.ts: export type AllowedChannels = \"doThing\" | \"doOtherThing\"; export interface ElectronApiFunction &#123; (...args: any[]): Promise&lt;any>; &#125; declare global &#123; interface Window &#123; ElectronAPI: &#123; [key in AllowedChannels]: ElectronApiFunction; &#125;; &#125; &#125; If you don’t know a lot about Typescript, this may be a bit confusing, so let’s break down what’s happening here. export interface ElectronApiFunction &#123; (...args: any[]): Promise&lt;any>; &#125; This is the signature that Electron IPC methods follow if you’re using asynchronous methods for them; anything can be a parameter, there can be any parameters, and anything can be returned from them (but in my case, it has to be a Promise). This is because I am only using Electron IPCs with two-way binding. If I used one-way binding, they’d all return void since they’re just calls to the main process to do something. This is mostly for niceness in main.ts and in any of my rendered files. It doesn’t actually do much in main.ts though, since ipcMain.handle already provides the typings for its own method. export type AllowedChannels = \"doThing\" | \"doOtherThing\"; This provides some really nice type-checking on my IPC channels though. Let’s look back at my preload.ts for a second: // no error addIpcRendererHandler(api, \"doThing\"); // Argument of type '\"foo\"' is not assignable to parameter of type 'AllowedChannels'. // vvvvv addIpcRendererHandler(api, \"foo\"); Great. I don’t have to worry about misspelling this string throughout my application anymore. If I do, my linter will just spit out an error! declare global &#123; interface Window &#123; ElectronAPI: &#123; [key in AllowedChannels]: ElectronAPIFunction; &#125;; &#125; &#125; This is really nice for your renderer process code. This piece of code essentially tells your linter “Hey, actually the window object will have an ElectronAPI property object attached to it, and this object will contain properties according to all strings in the AllowedChannels type, and these are all functions”. This means that in my renderer thread I can simply call window.ElectronAPI.doThing() and my linter will be okay with it despite me never actually having directly added anything to the window object. If I don’t add the above piece of code to my codebase, my linter will say “Property ElectronAPI does not exist on type Window &amp; typeof globalThis“. I can still call these functions though. The reason they still work is because we did put those functions on the window object, in preload.ts. Our editor just doesn’t know about that. So, what does this look like when I actually use these typed calls? Anywhere in my renderer process, I can simply call const result = await window.ElectronAPI.doThing(); …and everything just works now. One weird thing that I did run into is my default Electron configuration not working properly for setting up ipc channels. My Electron BrowserWindow object actually had contextIsolation set to false by default, which meant I could not use contextBridge.exposeInMainWorld in my application. I could also not directly set the window properties in preload.ts, which supposedly was the reason contextIsolation existed as an option in the first place. I had to re-enable it in the options to be able to expose the functions to the window object, but then it worked fine. For now, that’s as far as I have gotten with type safety in Electron. What I want to work on more is being able to define the correct signature for the functions I’m calling and have those return types show up in my editor as well (if window.ElectronAPI.doThing() is supposed to return a string, then I want vscode to give me an error if I don’t treat the return value as one). That’s something left for next time though. Now I have to deep dive into CSS hell to figure out how I am going to style this application I’m working on.","categories":[],"tags":[]},{"title":"Screen Shaders in Godot","slug":"screen-shaders-in-godot","date":"2023-07-18T12:00:00.000Z","updated":"2023-11-24T21:00:30.768Z","comments":true,"path":"2023/07/18/screen-shaders-in-godot/","link":"","permalink":"https://kamadoori.github.io/2023/07/18/screen-shaders-in-godot/","excerpt":"","text":"There are some premade options out there for PSX shaders in Godot. They allow you to apply materials to objects and apply shaders to the screen to emulate the rendering of the PSX. The premade options were unfortunately either somewhat lacking or had to be converted to be compatible with Godot 4. Trying to convert them from Godot Shader Language 1 to 2 was dramatic and plagued me with issues, so instead I decided to learn how to write these shaders from scratch. That was a very interesting process to go through. Getting StartedFirst off, I set up a sample project. No skybox, simple texture on floor and ability to move around. Nearly immediately I run into a problem; Godot’s post-processing stack is kinda nasty. To add custom post processing, you have to have a node stack like this: CanvasLayer └── SubViewportContainer &lt;-- Contains Screen space shader └── SubViewport └── Camera This doesn’t seem so bad, right? There are some problems with that though. Since your camera has to be under the viewport, you probably need your entire game under there. It’s manageable enough, although needs some finaggling when you’re loading other scenes, unless you are going to swap the entire scene out for another or pack your cameras into complete scenes with the CanvasLayers and SubViewports. Additionally, If you want to add another pass, you need another two nodes. The nodes are also in an initially illogical order. CanvasLayer └── SubViewportContainer &lt;-- Contains Second Pass └── SubViewport └── SubViewportContainer &lt;-- Contains First Pass └── SubViewport └── Camera The order makes some sense if you think about the viewport containers as translucent sheets of plastic; you have your camera screen, then you put your first pass on it, then you put your second pass on that. Okay, so I have my stack set up correctly. Time for a completely innocuous shader, one pass, to test everything. shader_type canvas_item; uniform sampler2D screen_texture: hint_screen_texture, filter_nearest, repeat_disable; void fragment() &#123; vec4 c = texture(screen_texture, SCREEN_UV); COLOR = c; &#125; Aaand… …nothing. We browse the Godot shader reference. Surely there’s something I’m missing. From https://docs.godotengine.org/en/stable/tutorials/shaders/custom_postprocessing.html : shader_type canvas_item; uniform sampler2D screen_texture : hint_screen_texture, repeat_disable, filter_nearest; // Blurs the screen in the X-direction. void fragment() &#123; vec3 col = texture(screen_texture, SCREEN_UV).xyz * 0.16; // [snipped some blur calculations here] COLOR.xyz = col; &#125; Okay.. I didn’t miss anything here I think. Maybe there’s just something about the alpha? Let’s try this. shader_type canvas_item; uniform sampler2D screen_texture : hint_screen_texture, repeat_disable, filter_nearest; void fragment() &#123; vec3 c = texture(screen_texture, SCREEN_UV).xyz; COLOR.rgb = c.rgb; &#125; Nope, still a gray screen. After bashing rocks together for a little bit longer, I found that actually, screen_texture is not the right variable to use. Instead I found the following at https://docs.godotengine.org/en/stable/tutorials/shaders/shader_reference/canvas_item_shader.html : Built-In Description sampler2D TEXTURE Default 2D texture. So what do you think this contains? What does “default 2D texture” mean? Surely it’s not the screen texture, that should be in screen_texture, right? Nope. This is the right variable. shader_type canvas_item; void fragment() &#123; vec3 c = texture(TEXTURE, SCREEN_UV).rgb; COLOR = c.rgb; &#125; Hooray, output. I wasn’t too happy at this point to be completely honest. The fact that the first sample on the wiki doesn’t work is very annoying, and something I alluded to when talking about Unity previously. At least I can get started on writing screen shaders now. Just a quick check that I’m not totally crazy: void fragment() &#123; vec4 c = texture(TEXTURE, SCREEN_UV); COLOR = vec4(FRAGCOORD.x * SCREEN_PIXEL_SIZE.x, FRAGCOORD.y * SCREEN_PIXEL_SIZE.y, 255, c.a); &#125; How lovely. How about some quantization? const float STEPS = 8.0; void fragment() &#123; vec2 approx = floor(FRAGCOORD.xy * SCREEN_PIXEL_SIZE * vec2(STEPS)) / vec2(STEPS); COLOR.rgb = vec3(approx, 255.0); &#125; Now that this is working, let’s finally try applying an effect to the actual screen texture. const float STEP = 8.0; void fragment() &#123; vec4 c = texture(TEXTURE, SCREEN_UV); vec4 rounded = floor(c * STEP) / STEP; COLOR = rounded; &#125; All good. Now I can work on creating my own shaders. I’ll have to look into how to apply dithering to a picture via screen space shaders, as that’s what the original PS1 did.","categories":[],"tags":[]},{"title":"Unity Struggles","slug":"unity-struggles","date":"2023-07-13T02:00:00.000Z","updated":"2023-11-24T21:00:30.768Z","comments":true,"path":"2023/07/13/unity-struggles/","link":"","permalink":"https://kamadoori.github.io/2023/07/13/unity-struggles/","excerpt":"","text":"I’m really starting to hate Unity. I have been using Unity on-and-off since somewhere around 2017.4 . The interesting thing to note is that I actually didn’t hate Unity all that much back in 2017. It didn’t have a lot of features I take for granted now (especially 2D, the 2D packages are actually quite nice) but I really didn’t miss those features. I could not be bothered to learn how to work with the Godot scripting language or node system in any capacity, so that was also in favor of Unity. Pretty recently I’m starting to feel like Godot is actually way more competent in many aspects. Getting StartedWant to get started in Godot? Download a zip, unzip it, run the executable. Create new project, wait 3 seconds after clicking Create, You’re completely done. Want a headstart? Download one of the example projects. No external tooling needed. You can use external tooling like VSCode to edit code, but I found that Godot’s language server in Godot 4 was kinda slow, so I just edit everything in-editor. Want to get started in Unity? Download the Unity Hub. Log into your Unity account. Register if you do not have one yet. Accept the license agreements. Accept the popup confirming you’re using a personal license. DO NOT let the hub install the version it’s about to install because it will most likely be a version that sucks. Instead download the LTS. If the LTS is the latest version, download the previous LTS. Either cope by using Visual Studio, cope by using Visual Studio Code’s stinkfest of a Unity setup or pay a monthly fee to your good friends over at JetBrains to use Rider. Pray that Unity does not break your code editor’s package setup this time around; I’ve found that the VSCode and Rider packages are constantly fighting with each other over stupid things. Wait upwards of 10 minutes for your project to finish being made, especially if you use the URP Core packages. Don’t expect the “micro projects” Unity advertised to show up or even work. Iteration SpeedGodot: Click play, have the game start up at your selected scene, go for it. Extremely fast for smaller projects. No compilation required since it’s all scripted. Unity: Has a really strong chance to have the upper hand here as the game is “loaded” when the engine’s up. Problem is that Unity’s domain compilation and reloading is so stupidly slow. Click play, wait five seconds in a completely fresh project, you can start testing. Add another five seconds to the iteration time if it’s right after you edit a script. And yes, you can disable domain reload on play. Problem is that this can introduce bugs that you might not be expecting. Although Unity already is pretty good at that to the point where power users suggest you just close and open the project every couple hours to refresh things and keep Unity running “fast”. Problem with that is that this can easily add another minute of waiting! Now why are the times I mentioned here important? Surely a couple of seconds to power on the game and get going isn’t a problem, is it? The problem is that when you constantly have to wait for things, you start doing other things. You don’t sit behind your PC waiting for a compilation to happen unless you just stood up for something. You grab a drink, grab a snack, go to the toilet, maybe browse the social media tab you have open in the background. And once in a while you’ll randomly forget that you were actually working on a Unity project. I don’t have this problem with Godot. I keep my focus because Godot isn’t trying to ruin my focus. Input SystemGodot’s input system is wonderful. Add action, add binding, listen for binding, done. You can mix and match event listening and polling. class_name Player var speed = 5.0 var jump_force = 4.5 func _input(event): if event.is_action_pressed(\"jump\"): jump() func _physics_process(delta): if Input.is_action_pressed(\"move_right\"): position.x += speed * delta move_and_slide() # Applies velocity and all that collision goodness for you. func _jump(): velocity.y = 4.5 Unity’s Input Manager is clunky in comparison. You’re essentially polling by default; it’s not reactive. public class Player : MonoBehaviour &#123; float speed = 5f; void Update() &#123; if(Input.GetButtonDown(\"jump\")) &#123; Jump(); &#125; if(Input.GetButtonDown(\"move_right\")) &#123; transform.Translate(new Vector3(speed * Time.deltaTime, 0, 0)); &#125; &#125; void Jump() &#123; // There's no built-in velocity unless you use Rigidbodies by the way. // So add a rigidbody component, restrict its rotation on the X and Z // axis to prevent your character from toppling over, and add a // reference to the rigidbody on this script. &#125; &#125; Unity’s Input System is even worse. Even though it seems pretty powerful and you can mix-and-match events, setting it up is a drag: public class Player : MonoBehaviour &#123; float speed = 5f; [SerializeField] InputAction moveAction; // Don't forget to assign this! void OnActionChange(object obj, InputActionChange change) &#123; if ( ((InputAction) obj).name == \"Jump\" &amp;&amp; change == InputActionChange.ActionStarted ) &#123; Jump(); &#125; &#125; void OnEnable() &#123; InputSystem.onActionChange += OnActionChange; moveAction.Enable(); &#125; void OnDisable() &#123; InputSystem.onActionChange -= OnActionChange; moveAction.Disable(); &#125; void Update() &#123; var value = moveAction.ReadValue&lt;Vector2>(); transform.Translate(new Vector3(value * speed * Time.deltaTime)); &#125; void Jump() &#123; // Still no built in velocity. &#125; &#125; On the note of the new Input System, it’s a drag to install and most packages won’t work with it! So when you install the new Input System, you’ll need to have both the Input System and Input Manager active in the background. When you install the System that’s another engine restart by the way, because Unity needs to enable the backend for it or something. In-engine modelingGodot has CSG nodes built-in. You can do boolean operations with each shape and rather quickly build up a small platform to work with. Although it’s nice to work with, I cannot call it ideal; you still want to do your actual worldbuilding outside of Godot. Godot does have terrain tools, but like Unity’s I feel like they’re.. just kinda usable. Just like how Cities: Skylines’s terrain tool is usable. Speaking of Unity; Probuilder. I don’t like it. It constantly freaks out and it annoys me. CommunityI feel like Unity makes up a lot of lost space in this regard. The amount of content available for Unity is outstanding. It’s just a shame that nearly all of it is outdated in one way or another. The Godot community is also.. weirdly elitist at times. I don’t know if it’s just me accidentally happening upon those “Well if you Googled this..” folks or not, but it’s kinda frustrating to see, especially for software that could really use an increase in community participation. You’ve got these people willing to do things in your community, just help them. It would’ve taken you as much time to solve some of these issues as it would’ve to google the issue yourself, check that the issue you googled is actually answered in the link you’re about to send and sending the link. DocumentationNeither documentation is ever properly up-to-date. It’s easy to pick a reason and stick it to me, but it’s also a massive issue for developers. If Godot breaks their shader code compatibility, I want an upgrade path. If Unity breaks their shader code compatibility, I want an upgrade path. I want to know what I can do in these engines. I don’t want to happen upon a function that is not explained in the docs but is explained in a blog post from 2014 made by someone who knows three times as much about the engine as core developers seem to do. So why use Unity?Assets. Godot is lacking in code assets pretty severely, especially with a major version bump earlier this year. Unity’s Asset Store has a lot of really good code assets. Art assets (textures, sprites, animations, music etc.) aren’t actually that big of a deal since: They are (usually) compatible between the two assets You can get them on so many different websites it’s actually laughable One interesting one for me is trying to develop a game with PSX style limitations to it. Affine texture mapping, vertex warping, dithering, color depth reduction, all that good stuff. One massive issue I run into with both engines is the complete lack of support for hard edge shadows which seems so extremely silly to me. Unity of course has a solution in the Asset store and PFFFTTTT- Yeah. I’m not spending that. It also only works with the Universal Rendering Pipeline. There aren’t too many PSX games with stencil shadows but it’s still an effect I absolutely adore. I guess using a shadow circle around the character would have to do. I think it can be done rather easily: cast a light on a separate layer on a mesh that’s also on that layer, make the mesh invisible but the shadow cast not. I think that’s feasible at least. So that kinda leaves me inbetween a rock and a hard place. I’m not adept with shaders, and learning to be would take a long time. Especially considering the difference in dialect between Godot’s shading language and Unity’s, and how both of these relate to GLSL&#x2F;HLSL. Just working with Unity puts me in a sour mood, but at least I get to watch Interstellar today. rev. 2023&#x2F;07&#x2F;13: spelling fix","categories":[],"tags":[]},{"title":"zzz","slug":"hello-world","date":"2023-07-11T22:00:00.000Z","updated":"2023-11-24T21:00:30.768Z","comments":true,"path":"2023/07/11/hello-world/","link":"","permalink":"https://kamadoori.github.io/2023/07/11/hello-world/","excerpt":"","text":"got angry at software and needed an outlet for all my problems","categories":[],"tags":[]}],"categories":[],"tags":[]}